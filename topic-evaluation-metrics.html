<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evaluation Metrics - Agentic AI Knowledge Hub</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/echarts/5.4.3/echarts.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        body { 
            font-family: 'Inter', sans-serif; 
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            overflow-x: hidden;
        }
        .code-font { font-family: 'JetBrains Mono', monospace; }
        .hero-overlay { 
            background: linear-gradient(135deg, rgba(16, 185, 129, 0.95) 0%, rgba(5, 150, 105, 0.95) 100%);
        }
        .topic-card { 
            transition: all 0.3s ease; 
            backdrop-filter: blur(10px);
            background: rgba(255, 255, 255, 0.9);
        }
        .topic-card:hover { 
            transform: translateY(-8px); 
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
        }
        .progress-bar {
            background: linear-gradient(90deg, #4CAF50 0%, #45a049 100%);
            border-radius: 10px;
            height: 8px;
            transition: width 0.3s ease;
        }
        .code-block {
            background: #1a202c;
            border-radius: 12px;
            padding: 1.5rem;
            margin: 1rem 0;
            overflow-x: auto;
        }
        .highlight-box {
            background: linear-gradient(135deg, #10b981 0%, #059669 100%);
            color: white;
            padding: 1.5rem;
            border-radius: 12px;
            margin: 1rem 0;
        }
        .metric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1.5rem;
            margin: 2rem 0;
        }
        .metric-card {
            background: white;
            border-radius: 12px;
            padding: 1.5rem;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
            border-left: 4px solid #10b981;
            transition: all 0.3s ease;
        }
        .metric-card:hover {
            transform: translateY(-4px);
            box-shadow: 0 8px 30px rgba(0, 0, 0, 0.15);
        }
        .metric-type {
            display: inline-block;
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            font-size: 0.75rem;
            font-weight: bold;
            text-transform: uppercase;
        }
        .type-classification { background: #dbeafe; color: #1e40af; }
        .type-regression { background: #dcfce7; color: #166534; }
        .type-nlp { background: #fef3c7; color: #d97706; }
        .type-rl { background: #fce7f3; color: #be185d; }
        .formula-box {
            background: #f8fafc;
            border: 1px solid #e2e8f0;
            border-radius: 8px;
            padding: 1rem;
            margin: 1rem 0;
            font-family: 'JetBrains Mono', monospace;
        }
        .nav-link {
            transition: all 0.3s ease;
            border-radius: 8px;
            padding: 0.5rem 1rem;
        }
        .nav-link:hover {
            background-color: rgba(16, 185, 129, 0.1);
            transform: translateX(4px);
        }
        .floating-element {
            animation: float 6s ease-in-out infinite;
        }
        @keyframes float {
            0%, 100% { transform: translateY(0px); }
            50% { transform: translateY(-20px); }
        }
        .stagger-item {
            opacity: 0;
            transform: translateY(30px);
        }
        .comparison-table {
            background: white;
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
            margin: 2rem 0;
        }
        .table-header {
            background: linear-gradient(135deg, #10b981 0%, #059669 100%);
            color: white;
            padding: 1rem;
        }
        .table-row {
            border-bottom: 1px solid #e2e8f0;
            padding: 1rem;
            transition: background-color 0.2s ease;
        }
        .table-row:hover {
            background-color: #f0fdf4;
        }
        .score-indicator {
            display: inline-block;
            width: 40px;
            height: 8px;
            border-radius: 4px;
            background: #e5e7eb;
            overflow: hidden;
        }
        .score-fill {
            height: 100%;
            border-radius: 4px;
            transition: width 0.3s ease;
        }
    </style>
</head>
<body class="min-h-screen">
    <!-- Navigation -->
    <nav class="bg-white shadow-lg sticky top-0 z-50">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <div class="flex justify-between h-16">
                <div class="flex items-center">
                    <div class="flex-shrink-0 flex items-center">
                        <i class="fas fa-brain text-2xl text-indigo-600 mr-3"></i>
                        <span class="text-xl font-bold text-gray-900">Agentic AI Hub</span>
                    </div>
                </div>
                <div class="flex items-center space-x-8">
                    <a href="index.html" class="nav-link text-gray-700 hover:text-indigo-600">Home</a>
                    <a href="topics.html" class="nav-link text-gray-700 hover:text-indigo-600">Topics</a>
                    <a href="about.html" class="nav-link text-gray-700 hover:text-indigo-600">About</a>
                    <a href="manage.html" class="nav-link text-gray-700 hover:text-indigo-600">Manage</a>
                </div>
            </div>
        </div>
    </nav>

    <!-- Hero Section -->
    <div class="relative h-64 hero-overlay flex items-center justify-center">
        <div class="absolute inset-0 bg-black opacity-20"></div>
        <div class="relative z-10 text-center text-white">
            <h1 class="text-4xl md:text-6xl font-bold mb-4 stagger-item">Evaluation Metrics</h1>
            <p class="text-xl md:text-2xl stagger-item">Measuring AI performance across all domains</p>
        </div>
        <div class="floating-element absolute top-10 right-10 text-white opacity-20">
            <i class="fas fa-chart-line text-6xl"></i>
        </div>
    </div>

    <!-- Main Content -->
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12">
        
        <!-- Introduction -->
        <div class="mb-12 stagger-item">
            <div class="highlight-box">
                <h2 class="text-2xl font-bold mb-4">What are Evaluation Metrics?</h2>
                <p class="text-lg leading-relaxed">
                    Evaluation metrics are quantitative measures used to assess the performance, quality, and effectiveness 
                    of AI systems. They provide objective ways to compare different models, track improvements, and ensure 
                    that AI systems meet their intended goals across various domains and applications.
                </p>
            </div>
        </div>

        <!-- Classification Metrics -->
        <div class="mb-12 stagger-item">
            <h2 class="text-3xl font-bold text-gray-900 mb-8">Classification Metrics</h2>
            
            <div class="metric-grid">
                <div class="metric-card">
                    <div class="flex items-center justify-between mb-4">
                        <h3 class="text-xl font-bold">Accuracy</h3>
                        <span class="metric-type type-classification">Classification</span>
                    </div>
                    <p class="text-gray-700 mb-4">
                        The ratio of correctly predicted instances to the total instances. Most intuitive but can be misleading with imbalanced datasets.
                    </p>
                    <div class="formula-box">
                        Accuracy = (TP + TN) / (TP + TN + FP + FN)
                    </div>
                    <div class="text-sm text-gray-600">
                        <strong>Best for:</strong> Balanced datasets where all classes are equally important
                    </div>
                </div>

                <div class="metric-card">
                    <div class="flex items-center justify-between mb-4">
                        <h3 class="text-xl font-bold">Precision</h3>
                        <span class="metric-type type-classification">Classification</span>
                    </div>
                    <p class="text-gray-700 mb-4">
                        The ratio of true positive predictions to all positive predictions. Measures the quality of positive predictions.
                    </p>
                    <div class="formula-box">
                        Precision = TP / (TP + FP)
                    </div>
                    <div class="text-sm text-gray-600">
                        <strong>Best for:</strong> When false positives are costly (e.g., medical diagnosis)
                    </div>
                </div>

                <div class="metric-card">
                    <div class="flex items-center justify-between mb-4">
                        <h3 class="text-xl font-bold">Recall (Sensitivity)</h3>
                        <span class="metric-type type-classification">Classification</span>
                    </div>
                    <p class="text-gray-700 mb-4">
                        The ratio of true positive predictions to all actual positive instances. Measures the ability to find all positive cases.
                    </p>
                    <div class="formula-box">
                        Recall = TP / (TP + FN)
                    </div>
                    <div class="text-sm text-gray-600">
                        <strong>Best for:</strong> When false negatives are costly (e.g., fraud detection)
                    </div>
                </div>

                <div class="metric-card">
                    <div class="flex items-center justify-between mb-4">
                        <h3 class="text-xl font-bold">F1-Score</h3>
                        <span class="metric-type type-classification">Classification</span>
                    </div>
                    <p class="text-gray-700 mb-4">
                        The harmonic mean of precision and recall. Provides a balanced measure when both precision and recall are important.
                    </p>
                    <div class="formula-box">
                        F1 = 2 × (Precision × Recall) / (Precision + Recall)
                    </div>
                    <div class="text-sm text-gray-600">
                        <strong>Best for:</strong> Imbalanced datasets where both precision and recall matter
                    </div>
                </div>
            </div>
        </div>

        <!-- Confusion Matrix Example -->
        <div class="mb-12 stagger-item">
            <h2 class="text-3xl font-bold text-gray-900 mb-8">Confusion Matrix Deep Dive</h2>
            
            <div class="code-block">
                <div class="flex items-center justify-between mb-4">
                    <span class="text-white font-semibold">Confusion Matrix Implementation</span>
                    <i class="fab fa-python text-yellow-400"></i>
                </div>
                <pre class="text-green-400 code-font text-sm"><code>from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# Generate sample predictions
y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]
y_pred = [1, 0, 0, 1, 0, 1, 1, 0, 1, 0]

# Create confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:")
print(cm)

# Calculate metrics from confusion matrix
TN, FP, FN, TP = cm.ravel()
accuracy = (TP + TN) / (TP + TN + FP + FN)
precision = TP / (TP + FP)
recall = TP / (TP + FN)
f1_score = 2 * (precision * recall) / (precision + recall)

print(f"\nAccuracy: {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1-Score: {f1_score:.3f}")

# Visualize confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()</code></pre>
            </div>
        </div>

        <!-- Regression Metrics -->
        <div class="mb-12 stagger-item">
            <h2 class="text-3xl font-bold text-gray-900 mb-8">Regression Metrics</h2>
            
            <div class="metric-grid">
                <div class="metric-card">
                    <div class="flex items-center justify-between mb-4">
                        <h3 class="text-xl font-bold">Mean Absolute Error (MAE)</h3>
                        <span class="metric-type type-regression">Regression</span>
                    </div>
                    <p class="text-gray-700 mb-4">
                        The average of absolute differences between predicted and actual values. Robust to outliers.
                    </p>
                    <div class="formula-box">
                        MAE = (1/n) × Σ|yᵢ - ŷᵢ|
                    </div>
                    <div class="text-sm text-gray-600">
                        <strong>Best for:</strong> When all errors are weighted equally
                    </div>
                </div>

                <div class="metric-card">
                    <div class="flex items-center justify-between mb-4">
                        <h3 class="text-xl font-bold">Mean Squared Error (MSE)</h3>
                        <span class="metric-type type-regression">Regression</span>
                    </div>
                    <p class="text-gray-700 mb-4">
                        The average of squared differences between predicted and actual values. Penalizes large errors more.
                    </p>
                    <div class="formula-box">
                        MSE = (1/n) × Σ(yᵢ - ŷᵢ)²
                    </div>
                    <div class="text-sm text-gray-600">
                        <strong>Best for:</strong> When large errors should be heavily penalized
                    </div>
                </div>

                <div class="metric-card">
                    <div class="flex items-center justify-between mb-4">
                        <h3 class="text-xl font-bold">Root Mean Squared Error (RMSE)</h3>
                        <span class="metric-type type-regression">Regression</span>
                    </div>
                    <p class="text-gray-700 mb-4">
                        The square root of MSE. Returns to original units and is more interpretable than MSE.
                    </p>
                    <div class="formula-box">
                        RMSE = √MSE = √[(1/n) × Σ(yᵢ - ŷᵢ)²]
                    </div>
                    <div class="text-sm text-gray-600">
                        <strong>Best for:</strong> When error magnitude matters in original units
                    </div>
                </div>

                <div class="metric-card">
                    <div class="flex items-center justify-between mb-4">
                        <h3 class="text-xl font-bold">R-squared (R²)</h3>
                        <span class="metric-type type-regression">Regression</span>
                    </div>
                    <p class="text-gray-700 mb-4">
                        The proportion of variance in the dependent variable explained by the model. Ranges from 0 to 1.
                    </p>
                    <div class="formula-box">
                        R² = 1 - (SS_res / SS_tot)
                    </div>
                    <div class="text-sm text-gray-600">
                        <strong>Best for:</strong> Understanding overall model performance and explanatory power
                    </div>
                </div>
            </div>
        </div>

        <!-- NLP Metrics -->
        <div class="mb-12 stagger-item">
            <h2 class="text-3xl font-bold text-gray-900 mb-8">Natural Language Processing Metrics</h2>
            
            <div class="metric-grid">
                <div class="metric-card">
                    <div class="flex items-center justify-between mb-4">
                        <h3 class="text-xl font-bold">BLEU Score</h3>
                        <span class="metric-type type-nlp">NLP</span>
                    </div>
                    <p class="text-gray-700 mb-4">
                        Measures the similarity between machine-generated text and reference translations using n-gram precision.
                    </p>
                    <div class="formula-box">
                        BLEU = BP × exp(Σ wₙ × log(pₙ))
                    </div>
                    <div class="text-sm text-gray-600">
                        <strong>Best for:</strong> Machine translation and text generation evaluation
                    </div>
                </div>

                <div class="metric-card">
                    <div class="flex items-center justify-between mb-4">
                        <h3 class="text-xl font-bold">ROUGE Score</h3>
                        <span class="metric-type type-nlp">NLP</span>
                    </div>
                    <p class="text-gray-700 mb-4">
                        Recall-Oriented Understudy for Gisting Evaluation. Measures overlap between generated and reference summaries.
                    </p>
                    <div class="formula-box">
                        ROUGE-N = Σ Σ count_match(n-gram) / Σ Σ count(n-gram)
                    </div>
                    <div class="text-sm text-gray-600">
                        <strong>Best for:</strong> Text summarization and document summarization tasks
                    </div>
                </div>

                <div class="metric-card">
                    <div class="flex items-center justify-between mb-4">
                        <h3 class="text-xl font-bold">Perplexity</h3>
                        <span class="metric-type type-nlp">NLP</span>
                    </div>
                    <p class="text-gray-700 mb-4">
                        Measures how well a probability model predicts a sample. Lower perplexity indicates better performance.
                    </p>
                    <div class="formula-box">
                        Perplexity = exp(-(1/N) × Σ log P(wᵢ|w₁...wᵢ₋₁))
                    </div>
                    <div class="text-sm text-gray-600">
                        <strong>Best for:</strong> Language modeling and text generation quality
                    </div>
                </div>

                <div class="metric-card">
                    <div class="flex items-center justify-between mb-4">
                        <h3 class="text-xl font-bold">BERTScore</h3>
                        <span class="metric-type type-nlp">NLP</span>
                    </div>
                    <p class="text-gray-700 mb-4">
                        Uses contextual embeddings to compute similarity between candidate and reference sentences.
                    </p>
                    <div class="formula-box">
                        BERTScore = (P × R × F1) using contextual embeddings
                    </div>
                    <div class="text-sm text-gray-600">
                        <strong>Best for:</span> Semantic similarity and text quality evaluation
                    </div>
                </div>
            </div>
        </div>

        <!-- Metric Comparison Table -->
        <div class="mb-12 stagger-item">
            <h2 class="text-3xl font-bold text-gray-900 mb-8">Metric Comparison & Selection Guide</h2>
            
            <div class="comparison-table">
                <div class="table-header grid grid-cols-6 gap-4 font-semibold">
                    <div>Metric</div>
                    <div>Type</div>
                    <div>Range</div>
                    <div>Sensitivity</div>
                    <div>Interpretability</div>
                    <div>Use Case</div>
                </div>
                
                <div class="table-row grid grid-cols-6 gap-4">
                    <div class="font-semibold">Accuracy</div>
                    <div>Classification</div>
                    <div>0-1</div>
                    <div>
                        <div class="score-indicator">
                            <div class="score-fill bg-green-500" style="width: 70%;"></div>
                        </div>
                    </div>
                    <div>
                        <div class="score-indicator">
                            <div class="score-fill bg-green-500" style="width: 95%;"></div>
                        </div>
                    </div>
                    <div>Balanced datasets</div>
                </div>
                
                <div class="table-row grid grid-cols-6 gap-4">
                    <div class="font-semibold">F1-Score</div>
                    <div>Classification</div>
                    <div>0-1</div>
                    <div>
                        <div class="score-indicator">
                            <div class="score-fill bg-yellow-500" style="width: 80%;"></div>
                        </div>
                    </div>
                    <div>
                        <div class="score-indicator">
                            <div class="score-fill bg-green-500" style="width: 85%;"></div>
                        </div>
                    </div>
                    <div>Imbalanced data</div>
                </div>
                
                <div class="table-row grid grid-cols-6 gap-4">
                    <div class="font-semibold">RMSE</div>
                    <div>Regression</div>
                    <div>0-∞</div>
                    <div>
                        <div class="score-indicator">
                            <div class="score-fill bg-red-500" style="width: 90%;"></div>
                        </div>
                    </div>
                    <div>
                        <div class="score-indicator">
                            <div class="score-fill bg-yellow-500" style="width: 75%;"></div>
                        </div>
                    </div>
                    <div>Large error penalty</div>
                </div>
                
                <div class="table-row grid grid-cols-6 gap-4">
                    <div class="font-semibold">BLEU</div>
                    <div>NLP</div>
                    <div>0-1</div>
                    <div>
                        <div class="score-indicator">
                            <div class="score-fill bg-yellow-500" style="width: 75%;"></div>
                        </div>
                    </div>
                    <div>
                        <div class="score-indicator">
                            <div class="score-fill bg-green-500" style="width: 80%;"></div>
                        </div>
                    </div>
                    <div>Machine translation</div>
                </div>
                
                <div class="table-row grid grid-cols-6 gap-4">
                    <div class="font-semibold">Perplexity</div>
                    <div>NLP</div>
                    <div>1-∞</div>
                    <div>
                        <div class="score-indicator">
                            <div class="score-fill bg-green-500" style="width: 85%;"></div>
                        </div>
                    </div>
                    <div>
                        <div class="score-indicator">
                            <div class="score-fill bg-red-500" style="width: 60%;"></div>
                        </div>
                    </div>
                    <div>Language modeling</div>
                </div>
            </div>
        </div>

        <!-- Performance Visualization -->
        <div class="mb-12 stagger-item">
            <h2 class="text-3xl font-bold text-gray-900 mb-8">Performance Comparison</h2>
            
            <div class="grid md:grid-cols-2 gap-8">
                <div class="topic-card p-6">
                    <h3 class="text-xl font-bold mb-4">Classification Metrics Comparison</h3>
                    <div id="classificationChart" style="height: 300px;"></div>
                </div>
                
                <div class="topic-card p-6">
                    <h3 class="text-xl font-bold mb-4">Regression Metrics Performance</h3>
                    <div id="regressionChart" style="height: 300px;"></div>
                </div>
            </div>
        </div>

        <!-- Navigation -->
        <div class="flex justify-between items-center mt-12 stagger-item">
            <a href="topic-ai-safety-ethics.html" class="flex items-center text-indigo-600 hover:text-indigo-800 transition-colors">
                <i class="fas fa-arrow-left mr-2"></i>
                Previous: AI Safety & Ethics
            </a>
            <div class="flex space-x-4">
                <a href="topics.html" class="bg-indigo-600 text-white px-6 py-2 rounded-lg hover:bg-indigo-700 transition-colors">
                    All Topics
                </a>
            </div>
            <a href="topic-deployment-strategies.html" class="flex items-center text-indigo-600 hover:text-indigo-800 transition-colors">
                Next: Deployment Strategies
                <i class="fas fa-arrow-right ml-2"></i>
            </a>
        </div>
    </div>

    <!-- Footer -->
    <footer class="bg-gray-900 text-white py-8">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
            <p>&copy; 2024 Agentic AI Knowledge Hub. Empowering the future of artificial intelligence.</p>
        </div>
    </footer>

    <script>
        // Initialize animations
        anime({
            targets: '.stagger-item',
            opacity: [0, 1],
            translateY: [30, 0],
            delay: anime.stagger(100),
            duration: 800,
            easing: 'easeOutQuart'
        });

        // Classification Metrics Chart
        const classificationChart = echarts.init(document.getElementById('classificationChart'));
        const classificationOption = {
            tooltip: { trigger: 'axis' },
            legend: { data: ['Model A', 'Model B', 'Model C'] },
            xAxis: {
                type: 'category',
                data: ['Accuracy', 'Precision', 'Recall', 'F1-Score']
            },
            yAxis: { type: 'value', name: 'Score', max: 1 },
            series: [
                { name: 'Model A', type: 'bar', data: [0.85, 0.82, 0.88, 0.85], itemStyle: { color: '#10b981' } },
                { name: 'Model B', type: 'bar', data: [0.78, 0.90, 0.70, 0.78], itemStyle: { color: '#3b82f6' } },
                { name: 'Model C', type: 'bar', data: [0.92, 0.85, 0.95, 0.89], itemStyle: { color: '#f59e0b' } }
            ]
        };
        classificationChart.setOption(classificationOption);

        // Regression Metrics Chart
        const regressionChart = echarts.init(document.getElementById('regressionChart'));
        const regressionOption = {
            tooltip: { trigger: 'axis' },
            legend: { data: ['MAE', 'MSE', 'RMSE'] },
            xAxis: {
                type: 'category',
                data: ['Linear', 'Random Forest', 'Neural Network', 'XGBoost']
            },
            yAxis: { type: 'value', name: 'Error Value' },
            series: [
                { name: 'MAE', type: 'line', data: [2.1, 1.8, 1.5, 1.3], itemStyle: { color: '#10b981' } },
                { name: 'MSE', type: 'line', data: [8.5, 6.2, 4.8, 3.9], itemStyle: { color: '#3b82f6' } },
                { name: 'RMSE', type: 'line', data: [2.9, 2.5, 2.2, 2.0], itemStyle: { color: '#f59e0b' } }
            ]
        };
        regressionChart.setOption(regressionOption);

        // Responsive charts
        window.addEventListener('resize', function() {
            classificationChart.resize();
            regressionChart.resize();
        });
    </script>
</body>
</html>